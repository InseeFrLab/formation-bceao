---
title: Introduction sur la place et les enjeux liées au *big data* à l'Insee
subtitle: |
  **[BCEAO - Jour 1]{.orange}**
author: "[Romain Avouac](https://github.com/avouacr), [Thomas Faria](https://github.com/ThomasFaria)"
date: "09/25/2023"
date-format: "D MMMM YYYY"
slide-number: true
lang: fr-FR
# for blind readers:
slide-tone: false
chalkboard: # press the B key to toggle chalkboard
  theme: whiteboard
# uncomment to use the multiplex mode:
# multiplex: true
format:
  onyxia-revealjs:
    output-file: index.html
controls: true
css: ../custom.css
from: markdown+emoji
ascii: true
execute: 
  echo: false
  warning: false
---

# Introduction

## Big data : de quoi parle-t-on ?

- De "nouvelles" données
  - enregistrements automatiques (GSM, géolocalisation, capteurs..)
  - contenus internet (webscraping, réseaux sociaux..)
  - images satellites
  - etc.

- Un phénomène pérenne porté par la croissance du numérique et des capacités techniques

## Big data : une définition

- [**Big data**]{.orange} : [*"Gestion et analyse d'un volume massif de données, souvent à une échelle bien supérieure à ce que les systèmes traditionnels peuvent traiter efficacement."*]{.blue2}

- [**Les 3 V**]{.orange} qui caractérisent les big data :
    - [**Volume**]{.orange} : quantités [**massives**]{.blue2} de données
    - [**Vitesse**]{.orange} : [**haute fréquence**]{.blue2}, jusqu'au temps réel
    - [**Variété**]{.orange} : [**diversité**]{.blue2} de [**sources**]{.blue2} et de [**formats**]{.blue2}

## Pourquoi s'intéresser à ces données ?

- [**Disponibilité**]{.orange} : réduction du coût et de la charge des enquêtes, des délais de publication (ex : nowcasting)

- [**Finesse**]{.orange} : statistiques localisées, sur des sous-population, plus fréquentes...

- [**Avancées méthodologiques**]{.orange} : convergence entre statistique et informatique (data science, machine learning)

- [**Exhaustivité**]{.orange} : compléter des déclarations d'enquêtes, créer de nouveaux indicateurs...

## Un retour de l'exhaustif ?

- Pré-XXe siècle : règne quasi-exclusif de l'exhaustivité
  - Recensements agricole, démographique, industriel

- XXe siècle : lent recul de l’exhaustivité au profit de l'échantillonnage
  - 1934 : article de référence sur la théorie des sondages (Neyman)
  - Développement des panels, études d'opinion, grandes enquêtes

- Fin XXe et début XXIe siècles : retour en grâce de l'exhaustif ?

## Début des réflexions des INS européens

- Mémorandum de Scheveningen (2013) : task force européenne sur le potentiel des big data

- Groupe de travail de l'UNECE (2014-2015) : "sandbox" pour manipuler des données concrètes

- ESSNET Big Data I (2016-2018) et II (2019-2021)
  - Préparer l'intégration des big data à la production statistique officielle
  - Projets pilotes sur une variété de sujets
  - Nombreuses [ressources](https://cros-legacy.ec.europa.eu/content/essnet-big-data-1_en)

# Défis

## Limites des sources big data

- Ni collectées ni conceptualisées à des fins de statistiques publiques
  - Le processus de génération des données n'est pas maîtrisé !


## Des données très différentes des statistiques publiques usuelles


- [**Processus de génération**]{.orange} des données non contrôlé
- Problème de [**représentativité**]{.orange} des différentes sous population
- Formats généralement [**complexes**]{.orange} et souvent [**changeants**]{.orange} ou non pérennes
- [**Pertinence**]{.orange} et [**complétude**]{.orange} parfois douteuses

::: {.callout-important}
## Différence centrale

:::

## Innovations nécessaires pour traiter ces données

- [**Techniques**]{.orange} : nouveaux langages de programmation, nouvelles infrastructures informatiques 
- [**Méthodologiques**]{.orange} : économétrie en grande dimension, analyse de données textuelles, analyse d'images
- [**Organisationnelles**]{.orange} : partenariats avec de nouveaux acteurs privés ou publics pour le partage de données

# Conclusion

## Une construction collective

- Des sources et des sujets variés qui impliquent de nombreuses dimensions (juridique, technique, méthodologique, organisationnelle, ...)

- Le statisticien public (data scientist?) ne peut incarner tous ces aspects

- Développer une synérgie entre toutes les parties prenantes (directions métiers, informatique, partenaires, ...)
